{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file creates two groups of models for two different subsets of the same dataset. The dataset is on the topic of heart disease. It was acquired through the API of https://data.world/uci/heart-disease using their python package \"datadotworld\".\n",
    "\n",
    "The dataset initially consisted of four sets for Hungary, Long Beach, Switzerland and Cleveland, which were combined into one.\n",
    "\n",
    "The 'bad columns' subset refers to features that require no medical examination. The quentions include age, sex, smoking, family history of heart disease, family history of diabetes, etc.\n",
    "\n",
    "The 'better columns' subset consists of medical metrics collected by professionals during patient examination. Better columns resulted in better recall for the models.\n",
    "\n",
    "Conclusion: Consult your doctor. Do not rely purely on the features from the 'bad columns' subset. Diagnosis requires medical examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import datetime\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.naive_bayes import GaussianNB   \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, make_scorer, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE, SelectKBest, chi2, SelectFromModel\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining scorers for use in Grid Search (currently only f1_scorer is used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "recall_scorer = make_scorer(recall_score, average='macro')\n",
    "precision_scorer = make_scorer(precision_score, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \n",
    "    # Shuffling data now to later split without shuffling\n",
    "    shuffled_cols_index = list(data.index)\n",
    "    random.shuffle(shuffled_cols_index)\n",
    "    data = data.iloc[shuffled_cols_index, :]\n",
    "    \n",
    "    # Splitting data into X and y\n",
    "    X = data.drop(columns = [58])\n",
    "    y = data[58]\n",
    "    \n",
    "    # Min-Max scaling the X data\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    # Replacing all 1,2,3,4 in y with 1 (i.e. if person has any degree of illness, replace degree with 1)\n",
    "    y = y.apply(lambda x: 0 if x==0 else 1)\n",
    "    \n",
    "    # Splitting data into train and test\n",
    "    data = train_test_split(X_scaled, y, test_size=0.3, shuffle=False)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHandler:\n",
    "    \n",
    "    def __init__(self, model, gs_params, data, model_params={}):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = data\n",
    "        self.model = model\n",
    "        self.gs_params = gs_params\n",
    "        self.model_params = model_params\n",
    "        self.f1_scorer = make_scorer(f1_score, average='macro')\n",
    "        self.gs = self._get_gs()\n",
    "        self.best_model = None\n",
    "\n",
    "\n",
    "    def _get_gs(self):\n",
    "        try:\n",
    "            gs_model = self.model(**self.model_params)\n",
    "            print(f'\\nPerforming Grid Search on {gs_model.__class__.__name__}')\n",
    "            gs = GridSearchCV(gs_model, self.gs_params, cv=5, verbose=10,  n_jobs=-1, refit=False, scoring = self.f1_scorer)\n",
    "            gs.fit(self.X_train, self.y_train)\n",
    "        except:\n",
    "            gs = None\n",
    "        return gs\n",
    "        \n",
    "    def get_best_model(self, fit=True):\n",
    "        try:\n",
    "            if self.gs == None:   #perform grid search if one isn't available\n",
    "                self.gs = self._get_gs()\n",
    "            best_model = self.model(**self.gs.best_params_, **self.model_params)   #define model using params from grid search\n",
    "        except:   #if grid search is impossible, define model with standard params\n",
    "            best_model = self.model(**self.model_params)\n",
    "        if fit==True:   #fit the model before returning\n",
    "            best_model.fit(self.X_train, self.y_train)\n",
    "        self.best_model = best_model\n",
    "        return best_model\n",
    "\n",
    "    \n",
    "    def predict(self, data):\n",
    "        return self.best_model.predict(data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def clf_report(y_test, pred):\n",
    "        return classification_report(y_test, pred)\n",
    "    \n",
    "    @staticmethod\n",
    "    def conf_matrix(y_test, pred):\n",
    "        return pd.DataFrame(confusion_matrix(y_test, pred))\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(y_test, pred):\n",
    "        return accuracy_score(y_test, pred)\n",
    "    \n",
    "    @staticmethod\n",
    "    def f1(y_test, pred):\n",
    "        return f1_score(y_test, pred, average='macro')\n",
    "    \n",
    "    @staticmethod\n",
    "    def recall(y_test, pred):\n",
    "        return recall_score(y_test, pred, average='macro')\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision(y_test, pred):\n",
    "        return precision_score(y_test, pred, average='macro')        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_handlers(data, *models):\n",
    "    handlers = {}\n",
    "    \n",
    "    # creating model handlers\n",
    "    for model_tuple in models:\n",
    "        model_name, model, params, model_settings = model_tuple\n",
    "        handler = ModelHandler(model, params, data, model_settings)\n",
    "        handlers[model_name] = handler\n",
    "            \n",
    "    # instantiating and fitting best models\n",
    "    for model_name, handler in handlers.items():\n",
    "        best_model = handler.get_best_model()\n",
    "        handler.best_model = best_model\n",
    "    \n",
    "    # creating an additional voting classifier using all the fitted models above\n",
    "    try:\n",
    "        print(\"Training Voting Classifier using best models...\")\n",
    "        estimators = [(key, model) for key, model in return_best_models(**handlers).items()]\n",
    "        model_params = dict(estimators=estimators, voting='hard')\n",
    "        handler = ModelHandler(model = VotingClassifier, gs_params={}, data=data, model_params=model_params)\n",
    "        handler.best_model = VotingClassifier(**model_params)\n",
    "        handler.best_model.fit(handler.X_train, handler.y_train)\n",
    "        handlers['voting'] = handler\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_best_models(**handlers):\n",
    "    best_models = {}\n",
    "    for model_name, handler in handlers.items():\n",
    "        try:\n",
    "            best_models[model_name] = handler.best_model\n",
    "        except:\n",
    "            handler.best_model = handler.get_best_model()\n",
    "            best_models[model_name] = handler.best_model\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_visualize(model_name, handlers):\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "\n",
    "    print(f'\\nStatistics and Confusion Matrix for model \"{model_name}\"')\n",
    "    test_pred = handlers[ model_name ].predict(handlers[ model_name ].X_test)\n",
    "    test_pred = pd.DataFrame(test_pred)\n",
    "    test_pred_recall = recall_score(handlers[ model_name ].y_test, test_pred, average='macro')\n",
    "    real = handlers[ model_name ].y_test\n",
    "\n",
    "    # calc confusion matrix\n",
    "    conf_matrix = handlers[ model_name ].conf_matrix(real, test_pred)\n",
    "    conf_matrix = pd.DataFrame(conf_matrix)\n",
    "\n",
    "    # print heatmap\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
    "    \n",
    "    print(handlers[model_name].clf_report(real, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(handlers, folder_path):\n",
    "    for model_name, handler in handlers.items():\n",
    "        model = handler.best_model\n",
    "        now = datetime.datetime.today()\n",
    "        now_str = now.strftime('%Y_%m_%d__%H_%M')\n",
    "        filename = f\"{folder_path}\\\\{model_name}__{now_str}.sav\"\n",
    "        joblib.dump(model, filename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conf_matrices(handlers, folder_path):\n",
    "    for model_name, handler in handlers.items():\n",
    "        conf_matrix = handler.conf_matrix(handler.y_test, handler.predict(handler.X_test))\n",
    "        now = datetime.datetime.today()\n",
    "        now_str = now.strftime('%Y_%m_%d__%H_%M')\n",
    "        filename = f\"{folder_path}\\\\{model_name}__{now_str}.sav\"\n",
    "        joblib.dump(conf_matrix, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clf_reports(handlers, folder_path):\n",
    "    for model_name, handler in handlers.items():\n",
    "        clf_report = handler.clf_report(handler.y_test, handler.predict(handler.X_test))\n",
    "        now = datetime.datetime.today()\n",
    "        now_str = now.strftime('%Y_%m_%d__%H_%M')\n",
    "        filename = f\"{folder_path}\\\\{model_name}__{now_str}.sav\"\n",
    "        joblib.dump(clf_report, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bad_cols = prepare_data(get_dataset.clean_bad_cols_df)\n",
    "data_better_cols = prepare_data(get_dataset.clean_better_cols_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing models for Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "log_params = {'penalty':['l1', 'l2', 'elasticnet', 'none'], \n",
    "              'C':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "log_model_settings = dict(max_iter = 1000, multi_class='multinomial') \n",
    "log_tuple = ('lr', LogisticRegression, log_params, log_model_settings)  \n",
    "\n",
    "\n",
    "# KNeighborsClassifier\n",
    "knn_params = {'n_neighbors': [i for i in range(3,17,2)]}\n",
    "knn_model_settings = dict()\n",
    "knn_tuple = ('knn', KNeighborsClassifier, knn_params, knn_model_settings) \n",
    "\n",
    "\n",
    "# GaussianNB (grid search is not applicable to GaussianNB)\n",
    "gauss_params = dict()\n",
    "gauss_model_settings = dict()\n",
    "gauss_tuple = ('gauss', GaussianNB, gauss_params, gauss_model_settings)\n",
    "\n",
    "\n",
    "# SVC\n",
    "svc_params = {'C':[1,10,100,1000],\n",
    "              'gamma':[1,0.1,0.001,0.0001], \n",
    "              'kernel':['linear','rbf']}\n",
    "svc_model_settings = dict()\n",
    "svc_tuple = 'svc', SVC, svc_params, svc_model_settings\n",
    "\n",
    "\n",
    "# DecisionTreeClassifier\n",
    "d_tree_params = {'criterion':['gini','entropy'],\n",
    "                 'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
    "d_tree_model_settings = dict()\n",
    "d_tree_tuple = ('d_tree', DecisionTreeClassifier, d_tree_params, d_tree_model_settings)\n",
    "\n",
    "\n",
    "# RandomForestClassifier\n",
    "r_forest_params = {'n_estimators': [50, 150],\n",
    "                    'max_features': ['sqrt', 0.25, 0.5, 0.75],\n",
    "                    'min_samples_split': [2, 4, 6]}\n",
    "r_forest_model_settings = dict()\n",
    "r_forest_tuple = ('r_forest', RandomForestClassifier, r_forest_params, r_forest_model_settings)\n",
    "\n",
    "\n",
    "# GradientBoostingClassifier\n",
    "g_boost_params = {'learning_rate':[0.15,0.1,0.05,0.01], \n",
    "                  'n_estimators':[100,250,500,750]}\n",
    "g_boost_settings = {}\n",
    "g_boost_tuple = ('g_boost', GradientBoostingClassifier, g_boost_params, g_boost_settings)\n",
    "\n",
    "\n",
    "# MLPClassifier\n",
    "nn_params = {'hidden_layer_sizes': [(50, 25, 5)],\n",
    "             'activation': ['tanh', 'relu'],\n",
    "             'solver': ['sgd', 'adam'],\n",
    "             'alpha': [0.0001, 0.05],\n",
    "             'learning_rate': ['constant','adaptive']}\n",
    "nn_model_settings = dict(max_iter=10000)\n",
    "nn_tuple = ('nn', MLPClassifier, nn_params, nn_model_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Handlers for 'bad columns' subset (the handler class performs grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on LogisticRegression\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0228s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 120 | elapsed:    1.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 118 out of 120 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0357s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on KNeighborsClassifier\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 out of  35 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  35 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  35 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  35 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  35 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0312s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on GaussianNB\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Performing Grid Search on SVC\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0511s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    6.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0367s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on DecisionTreeClassifier\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1864s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on RandomForestClassifier\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 118 out of 120 | elapsed:   19.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   19.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on GradientBoostingClassifier\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  80 | elapsed:   20.1s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   22.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on MLPClassifier\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  80 | elapsed:   40.8s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   44.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Voting Classifier using best models...\n",
      "\n",
      "Performing Grid Search on VotingClassifier\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.7s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.2s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': <__main__.ModelHandler object at 0x000001757DCDCFD0>, 'knn': <__main__.ModelHandler object at 0x000001757DBFC7C0>, 'gauss': <__main__.ModelHandler object at 0x000001757DCAC5E0>, 'svc': <__main__.ModelHandler object at 0x000001757DCC12B0>, 'd_tree': <__main__.ModelHandler object at 0x000001757DCFCAF0>, 'r_forest': <__main__.ModelHandler object at 0x000001757DD2F670>, 'g_boost': <__main__.ModelHandler object at 0x000001757DC89280>, 'nn': <__main__.ModelHandler object at 0x000001757DD3B0D0>, 'voting': <__main__.ModelHandler object at 0x000001757DD578E0>}\n"
     ]
    }
   ],
   "source": [
    "models = [log_tuple, knn_tuple, gauss_tuple, svc_tuple, d_tree_tuple, r_forest_tuple, g_boost_tuple, nn_tuple]\n",
    "handlers_bad_cols = return_handlers(data_bad_cols, *models)\n",
    "\n",
    "print(handlers_bad_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Handlers for 'better columns' subset (the handler class performs grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on LogisticRegression\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0228s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0585s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on KNeighborsClassifier\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  35 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  35 | elapsed:    0.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  35 | elapsed:    0.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  35 | elapsed:    0.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  35 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0213s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on GaussianNB\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Performing Grid Search on SVC\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0451s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   13.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0377s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on DecisionTreeClassifier\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on RandomForestClassifier\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 118 out of 120 | elapsed:   25.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   25.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on GradientBoostingClassifier\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  80 | elapsed:   34.3s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   38.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on MLPClassifier\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  80 | elapsed:  2.8min remaining:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Voting Classifier using best models...\n",
      "\n",
      "Performing Grid Search on VotingClassifier\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    9.7s remaining:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    9.9s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': <__main__.ModelHandler object at 0x000001757DCC1F10>, 'knn': <__main__.ModelHandler object at 0x000001757C8DADC0>, 'gauss': <__main__.ModelHandler object at 0x000001757DCCA610>, 'svc': <__main__.ModelHandler object at 0x000001757DCB04F0>, 'd_tree': <__main__.ModelHandler object at 0x000001757DD571F0>, 'r_forest': <__main__.ModelHandler object at 0x000001757DD1C6D0>, 'g_boost': <__main__.ModelHandler object at 0x000001757DD52550>, 'nn': <__main__.ModelHandler object at 0x000001757DD52FA0>, 'voting': <__main__.ModelHandler object at 0x000001757DDC3820>}\n"
     ]
    }
   ],
   "source": [
    "models = [log_tuple, knn_tuple, gauss_tuple, svc_tuple, d_tree_tuple, r_forest_tuple, g_boost_tuple, nn_tuple]\n",
    "handlers_better_cols = return_handlers(data_better_cols, *models)\n",
    "\n",
    "print(handlers_better_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics and Confusion Matrix for model \"nn\"\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60        56\n",
      "           1       0.67      0.63      0.65        68\n",
      "\n",
      "    accuracy                           0.63       124\n",
      "   macro avg       0.63      0.63      0.63       124\n",
      "weighted avg       0.63      0.63      0.63       124\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stats for 'bad columns' data (\"voting\" model)\n",
    "analyze_visualize('nn', handlers_bad_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics and Confusion Matrix for model \"voting\"\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73       125\n",
      "           1       0.75      0.85      0.80       145\n",
      "\n",
      "    accuracy                           0.77       270\n",
      "   macro avg       0.77      0.76      0.77       270\n",
      "weighted avg       0.77      0.77      0.77       270\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD4CAYAAADsBlOYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAARwUlEQVR4nO3deZRU5ZnH8e/TXdAsiqCMgI1RMzIaZdRjCGJI3HDB4EQTNzSjiJgeFTEZjlFxCdGZKDhGg3GZNIswLiA6LswYF1wxLiiKB1B06INBQAFBQUEFuuqZP7ps2ha6qst6uV39/j6ce7rqVnHroU/z6+d931u3zN0RkXiVJV2AiCRLISASOYWASOQUAiKRUwiIRC4V+gXWDDpcyw+BnT6vXdIlROGppU9Yvs/dvHpx3j/3bbp+N+/jhqBOQCRywTsBkShl0klXkDeFgEgI6dqkK8ibhgMiAbhn8t5yMbNJZrbKzBY02PcfZvaOmc0zs4fMrHODx0aZWY2ZvWtmx+U6vkJAJIRMJv8tt8nAwEb7ZgK93f0A4P+AUQBmth8wGNg/+3duN7Pypg6uEBAJwTP5b7kO5T4L+LjRvifd/asxxytAz+ztE4Fp7r7R3d8DaoC+TR1fISASQiad92ZmVWY2p8FW1cxXOxd4LHu7Elja4LFl2X3bpIlBkRDy+A1f/1T3aqC6kJcxsyuBWuCeQv4+KAREgvDtsDpgZucAJwADfMs1AZYDuzd4Ws/svm3ScEAkhOJODH6DmQ0ELgV+6u6fN3hoBjDYzCrMbC+gF/BqU8dSJyASQjOGA7mY2VTgCKCrmS0DRlO3GlABzDQzgFfc/Xx3f8vMpgNvUzdMGO7uTZ65pBAQCaGIZwy6+xlb2T2xief/Hvh9vsdXCIiEUMROIDSFgEgIJXTasEJAJIQCJ/ySoBAQCSDHXFyLohAQCUFzAiKR03BAJHLqBEQil96cdAV5UwiIhKDhgEjkNBwQiZw6AZHIKQRE4uaaGBSJnOYERCKn4YBI5NQJiEROnYBI5NQJiESuVhcVEYmbOgGRyGlOQCRy6gREIqdOQCRy6gREIqfVAZHI1X8+aMunEBAJQXMCIpFTCIhEThODIpFL6xOIROKm4YBI5BQCIpHTnIBI3DxTOucJlCVdgEirlMnkv+VgZpPMbJWZLWiwb2czm2lmi7Jfu2T3m5ndYmY1ZjbPzA7OdXyFgEgI6XT+W26TgYGN9l0OPO3uvYCns/cBjgd6Zbcq4I5cB1cIiIRQxE7A3WcBHzfafSIwJXt7CnBSg/3/5XVeATqbWY+mjq8QEAmhGSFgZlVmNqfBVpXHK3Rz9w+zt1cA3bK3K4GlDZ63LLtvm6KfGGx30qlUHDsI3EkveY/1N4+h40UjadP7IPzz9QCsv3kM6cU1CVda2srKyrj90T+xesUarhr6W7rv3o0rb7uCTl06sWj+Isb86gZqN5fOO+9yasYbiNy9Gqgu/KXczazgmcioO4GyXbrS7p9OZt2vq1g3fCiUlVFx+FEAfD7pDtaNOI91I85TABTBz4adxPs1W35B/XLUefz3hAcZ8uOhfLZ2PccPbjzkLXFFHA5sw8qv2vzs11XZ/cuB3Rs8r2d23zblDAEz29fMLsvOON6Svf29AgtvecrLsbYVUFaOVVSQWbM66Ypana7du3LIUX35y9TH6vcd1P9AZj36AgBPPjCT/scdmlR5YWQ8/60wM4Ah2dtDgEca7D87u0rQD1jXYNiwVU2GgJldBkwDDHg1uxkw1cwub+rvloLMmtV8+eA0ukyeTpe7H8Q3bGDz3DkAdDj7PHa6dRIdfjkcUm0SrrS0Xfi78xl/3YT6tfNOXTqx/tMNZNJ1vwVXf7iaXbp3TbLE4ivi6oCZTQVeBvYxs2VmNgwYAxxjZouAo7P3Af4CLAZqgPHAhbmOn2tOYBiwv7t/7SNWzewm4K0GL9y46Crqlif4Q+9eDPlOk5OTibEddqBtvx/xybmD8Q3r2XHUNbQ98hg+n1yNf/IxpNrQccQltD/1TL6YOiX3AeUbDhlwCGvXrGXR/BoO7HdA0uVsN17E04bd/YxtPDRgK891YHhzjp8rBDLAbsCSRvt7ZB/bqoYTHWsGHd5iT51qc1Af0is/xD9dB8DGl16gzfd6s+nZmXVPqN3Mxqceo/3PT0+wytLWu89+HHpMP/oe+QPaVrSlw44dGH7NBezQqSNl5WVk0hm69ujKmhWtbBhWQmcM5gqBXwNPZ1uOr2Z1vgPsDVwUsK7tIvPRSlL77AcVFbBxI20OPJh0zbtYl53rOgGgbb8fkV7yXsKVlq6JY+9k4tg7ATiw3wGc+i+ncP3FY7n6jis5bNCPeW7G8xx7yjG89OTLCVdaZK3lvQPu/riZ/QPQly1rjcuB19y9dN4wvQ217y5k04vP03nceDydJr24hi8f+x86XXsDtlNnANLv1bD+1puSLbQVmnD9RK687QqG/uYcahbU8Ni0J5IuqbhKqBMwD3xBxJY8HGgtTp/XLukSovDU0ics3+du+O3gvH/uO147Le/jhhD9yUIiQbSW4YCIFKiEhgMKAZEAirlEGJpCQCQEdQIikVMIiEROlxwXiVspXWNQISASgkJAJHJaHRCJnDoBkcgpBETi5mkNB0Tipk5AJG5aIhSJnUJAJHKlMyWgEBAJwWtLJwUUAiIhlE4GKAREQtDEoEjs1AmIxE2dgEjs1AmIxM1L6FPWFQIiAZTQFccVAiJBKARE4qZOQCRyCgGRyHk60Y8XbBaFgEgA6gREIueZ0ukEypIuQKQ18kz+Wy5m9q9m9paZLTCzqWbWzsz2MrPZZlZjZveZWdtCa1UIiATgbnlvTTGzSuBioI+79wbKgcHAWOBmd98b+AQYVmitCgGRAIrZCVA3bG9vZimgA/AhcBTwQPbxKcBJhdaqEBAJIJO2vDczqzKzOQ22qq+O4+7LgRuB96n7z78OeB1Y615/cvIyoLLQWjUxKBJAcyYG3b0aqN7aY2bWBTgR2AtYC9wPDPz2FW6hEBAJoIirA0cD77n7RwBm9iDQH+hsZqlsN9ATWF7oC2g4IBKAe/5bDu8D/cysg5kZMAB4G3gWOCX7nCHAI4XWqhAQCcAzlvfW5HHcZ1M3AfgGMJ+6/7PVwGXASDOrAXYBJhZaq4YDIgHkWvpr3rF8NDC60e7FQN9iHF8hIBJAWu8dEIlbMTuB0BQCIgGU0nsHFAIiAeQx699iKAREAlAnIBK5dKZ0Vt8VAiIBaDggErmMVgdE4qYlQpHIaTjQQLeZNaFfInpffPBC0iVIIxoOiEROqwMikSuh0YBCQCQEDQdEIqfVAZHIldAHECkEREJw1AmIRK1WwwGRuKkTEImc5gREIqdOQCRy6gREIpdWJyAStxK6uphCQCSEjDoBkbjpDUQikdPEoEjkMqbhgEjU0kkX0AwKAZEAtDogEjmtDohETqsDIpHTcEAkcqW0RFg610UWKSFpy3/Lh5l1NrMHzOwdM1toZoea2c5mNtPMFmW/dimkVoWASACZZmx5Ggc87u77AgcCC4HLgafdvRfwdPZ+sykERAIoZgiY2U7AYcBEAHff5O5rgROBKdmnTQFOKqRWhYBIAG75b2ZWZWZzGmxVjQ63F/ARcKeZzTWzCWbWEejm7h9mn7MC6FZIrZoYFAmgOROD7l4NVDfxlBRwMDDC3Web2Tgatf7u7mZW0MqkOgGRANLN2PKwDFjm7rOz9x+gLhRWmlkPgOzXVYXUqhAQCSBj+W+5uPsKYKmZ7ZPdNQB4G5gBDMnuGwI8UkitGg6IBBDgPIERwD1m1hZYDAyl7pf4dDMbBiwBTivkwAoBkQCKHQLu/ibQZysPDfi2x1YIiASg9w6IRE7vHRCJnC4qIhK5TAkNCBQCIgGU0rsIFQIiAZROH6AQEAlCnYBI5GoLO40/EQoBkQBKJwIUAiJBaDggEjktEYpErnQiQCEgEoSGAyKRS5dQL6AQEAlAnYBI5FydgEjc1AmUiJ49d2PypHHs2q0r7s6ECffwp1snMvb6qxh0wjFs2rSJxYuXMOy8kaxb92nS5ZaUq667iVkvvsrOXTrz8N3/CcCNt07g+Rdnk2qTYvfKHvz7FSPptOMOzH/7XX439hag7jfohef+gqMP759k+d9aKS0RmnvYYlNtK1vsd6N7913p0X1X5r65gB126Mirsx/n5FPOpWdlD5559kXS6TTXX3cFAKOuuC7harftiw9eSLqEb5jz5nw6tG/PFf92Y30IvDj7dQ75/kGkUuXcdPtEAEZeOIwvvvySNqk2pFLlfLT6Y04eciHPPHIPqVR5kv+Eb2jT9bt5Xyrkgj1Py/vn/o6/TU/0EiRRX214xYpVzH1zAQDr12/gnXcWUblbd2Y+NYt0uu6yEK/MfoPKyh5JllmS+hz0j+zUacev7et/yPfr/2MfsP++rFy1GoD27drV79+4aRNYCV2WZxtq8by3pEU9HGhojz16ctCBvZn96tyv7R96zmCm3z8joapar4cefZKBAw6vvz/vrXe4+rqb+WDlKq6/+pIW1wU0VylNDBbcCZjZ0CYeq/9YpUxmQ6Evsd107NiB6feNZ+Qlo/nss/X1+0ddfjG1tbXce++DCVbX+vx5ylTKy8s54dgj6/cdsP++PHLPn5k2YRwT7prOxo2bEqzw2wvwgaTBfJvhwDXbesDdq929j7v3KSvr+C1eIrxUKsX9941n6tSHePjhx+r3n33WaQz6ydGcdfZFCVbX+jz86ExmvfgqY0dfim2l7f/7Pb9Dh/btWbT4b9u/uCLyZvxJWpPDATObt62HKPDDD1ua8dV/YOE7Nfxx3JaPgjvu2CO45JILOGrAyXzxxZcJVte6/PWVOUy6934m33oD7du1q9+/7IMVdN/170ilyvlgxUreW7KUyh6l/ePVEn7D56vJ1QEzWwkcB3zS+CHgJXffLdcLtOTVgf4//AHPP/cw8+a/TSZTV+bVV4/h5puupaKigjUf1/2zZ89+g+EXFfTR79tFS1wd+M3oMbw2dx5r137KLjt35sJhZzHhrvvYtHkznTt1AuqGAKMvHcGMx59m4l3TSaVSlJUZ5w89kwGH/TDhf8E3NWd14J/3+HneP/d3L3kw0ZnQXCEwEbjT3f+6lcfudfczc71ASw6B1qIlhkBr1JwQOHOPn+X9c3/vkocSDYEmhwPuPqyJx3IGgEisWsJYP19aIhQJoJTmBBQCIgGU0mnDCgGRADQcEIlcOvB7copJISASgIYDIpHTxKBI5EppTiDqtxKLhJLB897yYWblZjbXzP43e38vM5ttZjVmdp+ZtS20VoWASADunveWp18BCxvcHwvc7O57U3da/zZP7MtFISASQBrPe8vFzHoCg4AJ2fsGHAU8kH3KFOCkQmtVCIgE0JzhQMPrb2S3qkaH+yNwKVvmG3cB1rp7bfb+MqCy0Fo1MSgSQHOu3enu1UD11h4zsxOAVe7+upkdUZTiGlEIiARQxPME+gM/NbOfAO2ATsA4oLOZpbLdQE9geaEvoOGASADFurKQu49y957uvicwGHjG3X8BPAuckn3aEOCRQmtVCIgEkHbPeyvQZcBIM6uhbo5gYqEH0nBAJIAQpw27+3PAc9nbi4G+xTiuQkAkAL13QCRyoT/Zq5gUAiIBqBMQiVwpvYFIISASQNpL583ECgGRADQnIBI5zQmIRE5zAiKRy2g4IBI3dQIikdPqgEjkNBwQiZyGAyKRUycgEjl1AiKRS3s66RLyphAQCUCnDYtETqcNi0ROnYBI5LQ6IBI5rQ6IRE6nDYtETnMCIpHTnIBI5NQJiERO5wmIRE6dgEjktDogEjlNDIpETsMBkcjpjEGRyKkTEIlcKc0JWCkl1vZiZlXuXp10Ha2ZvsctR1nSBbRQVUkXEAF9j1sIhYBI5BQCIpFTCGydxqrh6XvcQmhiUCRy6gREIqcQEImcQqABMxtoZu+aWY2ZXZ50Pa2RmU0ys1VmtiDpWqSOQiDLzMqB24Djgf2AM8xsv2SrapUmAwOTLkK2UAhs0ReocffF7r4JmAacmHBNrY67zwI+TroO2UIhsEUlsLTB/WXZfSKtmkJAJHIKgS2WA7s3uN8zu0+kVVMIbPEa0MvM9jKztsBgYEbCNYkEpxDIcvda4CLgCWAhMN3d30q2qtbHzKYCLwP7mNkyMxuWdE2x02nDIpFTJyASOYWASOQUAiKRUwiIRE4hIBI5hYBI5BQCIpH7f/++CFgiIz+LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stats for 'better columns' data (\"voting\" model)\n",
    "analyze_visualize('voting', handlers_better_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handlers_bad_cols['voting'].predict([[1,2,3,4,5,6,7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models(handlers_bad_cols, \"models\\\\bad_col_models\")\n",
    "save_models(handlers_better_cols, \"models\\\\better_col_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_conf_matrices(handlers_bad_cols, \"models\\\\bad_col_conf_matrices\")\n",
    "save_conf_matrices(handlers_better_cols, \"models\\\\better_col_conf_matrices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_clf_reports(handlers_bad_cols, \"models\\\\bad_col_clf_reports\")\n",
    "save_clf_reports(handlers_better_cols, \"models\\\\better_col_clf_reports\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}