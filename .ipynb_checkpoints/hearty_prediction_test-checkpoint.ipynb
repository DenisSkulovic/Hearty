{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file creates two groups of models for two different subsets of the same dataset. The dataset is on the topic of heart disease. It was acquired through the API of https://data.world/uci/heart-disease using their python package \"datadotworld\".\n",
    "\n",
    "The dataset initially consisted of four sets for Hungary, Long Beach, Switzerland and Cleveland, which were combined into one.\n",
    "\n",
    "The 'bad columns' subset refers to features that require no medical examination. The quentions include age, sex, smoking, family history of heart disease, family history of diabetes, etc.\n",
    "\n",
    "The 'better columns' subset consists of medical metrics collected by professionals during patient examination. Better columns resulted in better recall for the models.\n",
    "\n",
    "Conclusion: Consult your doctor. Do not rely purely on the features from the 'bad columns' subset. Diagnosis requires medical examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import datetime\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.naive_bayes import GaussianNB   \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, make_scorer, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold, RFE, SelectKBest, chi2, SelectFromModel\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hearty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining scorers for use in Grid Search (currently only f1_scorer is used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scorer = make_scorer(accuracy_score)\n",
    "f1_scorer = make_scorer(f1_score, average='macro')\n",
    "recall_scorer = make_scorer(recall_score, average='macro')\n",
    "precision_scorer = make_scorer(precision_score, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \n",
    "    # Shuffling data now to later split without shuffling\n",
    "    shuffled_cols_index = list(data.index)\n",
    "    random.shuffle(shuffled_cols_index)\n",
    "    data = data.iloc[shuffled_cols_index, :]\n",
    "    \n",
    "    # Splitting data into X and y\n",
    "    X = data.drop(columns = [58])\n",
    "    y = data[58]\n",
    "    \n",
    "    # Min-Max scaling the X data\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    # Replacing all 1,2,3,4 in y with 1 (i.e. if person has any degree of illness, replace degree with 1)\n",
    "    y = y.apply(lambda x: 0 if x==0 else 1)\n",
    "    \n",
    "    # Splitting data into train and test\n",
    "    data = train_test_split(X_scaled, y, test_size=0.3, shuffle=False)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHandler:\n",
    "    \n",
    "    def __init__(self, model, gs_params, data, model_params={}):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = data\n",
    "        self.model = model\n",
    "        self.gs_params = gs_params\n",
    "        self.model_params = model_params\n",
    "        self.f1_scorer = make_scorer(f1_score, average='macro')\n",
    "        self.gs = self._get_gs()\n",
    "        self.best_model = None\n",
    "\n",
    "\n",
    "    def _get_gs(self):\n",
    "        try:\n",
    "            gs_model = self.model(**self.model_params)\n",
    "            print(f'\\nPerforming Grid Search on {gs_model.__class__.__name__}')\n",
    "            gs = GridSearchCV(gs_model, self.gs_params, cv=5, verbose=10,  n_jobs=-1, refit=False, scoring = self.f1_scorer)\n",
    "            gs.fit(self.X_train, self.y_train)\n",
    "        except:\n",
    "            gs = None\n",
    "        return gs\n",
    "        \n",
    "    def get_best_model(self, fit=True):\n",
    "        try:\n",
    "            if self.gs == None:   #perform grid search if one isn't available\n",
    "                self.gs = self._get_gs()\n",
    "            best_model = self.model(**self.gs.best_params_, **self.model_params)   #define model using params from grid search\n",
    "        except:   #if grid search is impossible, define model with standard params\n",
    "            best_model = self.model(**self.model_params)\n",
    "        if fit==True:   #fit the model before returning\n",
    "            best_model.fit(self.X_train, self.y_train)\n",
    "        self.best_model = best_model\n",
    "        return best_model\n",
    "\n",
    "    \n",
    "    def predict(self, data):\n",
    "        return self.best_model.predict(data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def clf_report(y_test, pred):\n",
    "        return classification_report(y_test, pred)\n",
    "    \n",
    "    @staticmethod\n",
    "    def conf_matrix(y_test, pred):\n",
    "        return pd.DataFrame(confusion_matrix(y_test, pred))\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(y_test, pred):\n",
    "        return accuracy_score(y_test, pred)\n",
    "    \n",
    "    @staticmethod\n",
    "    def f1(y_test, pred):\n",
    "        return f1_score(y_test, pred, average='macro')\n",
    "    \n",
    "    @staticmethod\n",
    "    def recall(y_test, pred):\n",
    "        return recall_score(y_test, pred, average='macro')\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision(y_test, pred):\n",
    "        return precision_score(y_test, pred, average='macro')        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_handlers(data, *models):\n",
    "    handlers = {}\n",
    "    \n",
    "    # creating model handlers\n",
    "    for model_tuple in models:\n",
    "        model_name, model, params, model_settings = model_tuple\n",
    "        handler = ModelHandler(model, params, data, model_settings)\n",
    "        handlers[model_name] = handler\n",
    "            \n",
    "    # instantiating and fitting best models\n",
    "    for model_name, handler in handlers.items():\n",
    "        best_model = handler.get_best_model()\n",
    "        handler.best_model = best_model\n",
    "    \n",
    "    # creating an additional voting classifier using all the fitted models above\n",
    "    try:\n",
    "        print(\"Training Voting Classifier using best models...\")\n",
    "        estimators = [(key, model) for key, model in return_best_models(**handlers).items()]\n",
    "        model_params = dict(estimators=estimators, voting='hard')\n",
    "        handler = ModelHandler(model = VotingClassifier, gs_params={'voting':['hard','soft']}, data=data, model_params=model_params)\n",
    "        handler.best_model = VotingClassifier(**handler.gs.best_params_, **model_params)\n",
    "        handler.best_model.fit(handler.X_train, handler.y_train)\n",
    "        handlers['voting'] = handler\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_best_models(**handlers):\n",
    "    best_models = {}\n",
    "    for model_name, handler in handlers.items():\n",
    "        try:\n",
    "            best_models[model_name] = handler.best_model\n",
    "        except:\n",
    "            handler.best_model = handler.get_best_model()\n",
    "            best_models[model_name] = handler.best_model\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_visualize(model_name, handlers):\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "\n",
    "    print(f'\\nStatistics and Confusion Matrix for model \"{model_name}\"')\n",
    "    test_pred = handlers[ model_name ].predict(handlers[ model_name ].X_test)\n",
    "    test_pred = pd.DataFrame(test_pred)\n",
    "    test_pred_recall = recall_score(handlers[ model_name ].y_test, test_pred, average='macro')\n",
    "    real = handlers[ model_name ].y_test\n",
    "\n",
    "    # calc confusion matrix\n",
    "    conf_matrix = handlers[ model_name ].conf_matrix(real, test_pred)\n",
    "    conf_matrix = pd.DataFrame(conf_matrix)\n",
    "\n",
    "    # print heatmap\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
    "    \n",
    "    print(handlers[model_name].clf_report(real, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(handlers, folder_path):\n",
    "    for model_name, handler in handlers.items():\n",
    "        model = handler.best_model\n",
    "        now = datetime.datetime.today()\n",
    "        now_str = now.strftime('%Y_%m_%d__%H_%M')\n",
    "        filename = f\"{folder_path}\\\\{model_name}__{now_str}.sav\"\n",
    "        joblib.dump(model, filename)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bad_cols = prepare_data(hearty.clean_bad_cols_df)\n",
    "data_better_cols = prepare_data(hearty.clean_better_cols_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing models for Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "log_params = {'penalty':['l1', 'l2', 'elasticnet', 'none'], \n",
    "              'C':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "log_model_settings = dict(max_iter = 1000, multi_class='multinomial') \n",
    "log_tuple = ('lr', LogisticRegression, log_params, log_model_settings)  \n",
    "\n",
    "\n",
    "# KNeighborsClassifier\n",
    "knn_params = {'n_neighbors': [i for i in range(3,17,2)]}\n",
    "knn_model_settings = dict()\n",
    "knn_tuple = ('knn', KNeighborsClassifier, knn_params, knn_model_settings) \n",
    "\n",
    "\n",
    "# GaussianNB (grid search is not applicable to GaussianNB)\n",
    "gauss_params = dict()\n",
    "gauss_model_settings = dict()\n",
    "gauss_tuple = ('gauss', GaussianNB, gauss_params, gauss_model_settings)\n",
    "\n",
    "\n",
    "# SVC\n",
    "svc_params = {'C':[1,10,100,1000],\n",
    "              'gamma':[1,0.1,0.001,0.0001], \n",
    "              'kernel':['linear','rbf']}\n",
    "svc_model_settings = dict()\n",
    "svc_tuple = 'svc', SVC, svc_params, svc_model_settings\n",
    "\n",
    "\n",
    "# DecisionTreeClassifier\n",
    "d_tree_params = {'criterion':['gini','entropy'],\n",
    "                 'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
    "d_tree_model_settings = dict()\n",
    "d_tree_tuple = ('d_tree', DecisionTreeClassifier, d_tree_params, d_tree_model_settings)\n",
    "\n",
    "\n",
    "# RandomForestClassifier\n",
    "r_forest_params = {'n_estimators': [50, 150],\n",
    "                    'max_features': ['sqrt', 0.25, 0.5, 0.75],\n",
    "                    'min_samples_split': [2, 4, 6]}\n",
    "r_forest_model_settings = dict()\n",
    "r_forest_tuple = ('r_forest', RandomForestClassifier, r_forest_params, r_forest_model_settings)\n",
    "\n",
    "\n",
    "# GradientBoostingClassifier\n",
    "g_boost_params = {'learning_rate':[0.15,0.1,0.05,0.01], \n",
    "                  'n_estimators':[100,250,500,750]}\n",
    "g_boost_settings = {}\n",
    "g_boost_tuple = ('g_boost', GradientBoostingClassifier, g_boost_params, g_boost_settings)\n",
    "\n",
    "\n",
    "# MLPClassifier\n",
    "nn_params = {'hidden_layer_sizes': [(50, 25, 5)],\n",
    "             'activation': ['tanh', 'relu'],\n",
    "             'solver': ['sgd', 'adam'],\n",
    "             'alpha': [0.0001, 0.05],\n",
    "             'learning_rate': ['constant','adaptive']}\n",
    "nn_model_settings = dict(max_iter=10000)\n",
    "nn_tuple = ('nn', MLPClassifier, nn_params, nn_model_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Handlers for 'bad columns' subset (the handler class performs grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on LogisticRegression\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1899s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1057s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 120 | elapsed:    8.0s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on KNeighborsClassifier\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1766s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  35 | elapsed:    0.4s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  35 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  35 | elapsed:    0.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  35 | elapsed:    0.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0219s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0369s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on GaussianNB\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Performing Grid Search on SVC\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1267s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 145 out of 160 | elapsed:   12.6s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   25.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0718s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on DecisionTreeClassifier\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1227s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on RandomForestClassifier\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 118 out of 120 | elapsed:   14.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   14.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on GradientBoostingClassifier\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  80 | elapsed:   15.1s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   16.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on MLPClassifier\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  80 | elapsed:   47.7s remaining:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   53.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Voting Classifier using best models...\n",
      "\n",
      "Performing Grid Search on VotingClassifier\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    4.5s remaining:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    6.7s remaining:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    7.5s remaining:    3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': LogisticRegression(C=10, max_iter=1000, multi_class='multinomial'), 'knn': KNeighborsClassifier(), 'gauss': GaussianNB(), 'svc': SVC(C=10, gamma=1), 'd_tree': DecisionTreeClassifier(max_depth=5), 'r_forest': RandomForestClassifier(max_features='sqrt', min_samples_split=4,\n",
      "                       n_estimators=150), 'g_boost': GradientBoostingClassifier(learning_rate=0.01, n_estimators=250), 'nn': MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(50, 25, 5),\n",
      "              max_iter=10000), 'voting': VotingClassifier(estimators=[('lr',\n",
      "                              LogisticRegression(C=10, max_iter=1000,\n",
      "                                                 multi_class='multinomial')),\n",
      "                             ('knn', KNeighborsClassifier()),\n",
      "                             ('gauss', GaussianNB()),\n",
      "                             ('svc', SVC(C=10, gamma=1)),\n",
      "                             ('d_tree', DecisionTreeClassifier(max_depth=5)),\n",
      "                             ('r_forest',\n",
      "                              RandomForestClassifier(max_features='sqrt',\n",
      "                                                     min_samples_split=4,\n",
      "                                                     n_estimators=150)),\n",
      "                             ('g_boost',\n",
      "                              GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                                         n_estimators=250)),\n",
      "                             ('nn',\n",
      "                              MLPClassifier(activation='tanh', alpha=0.05,\n",
      "                                            hidden_layer_sizes=(50, 25, 5),\n",
      "                                            max_iter=10000))])}\n"
     ]
    }
   ],
   "source": [
    "models = [log_tuple, knn_tuple, gauss_tuple, svc_tuple, d_tree_tuple, r_forest_tuple, g_boost_tuple, nn_tuple]\n",
    "handlers_bad_cols = return_handlers(data_bad_cols, *models)\n",
    "\n",
    "print(handlers_bad_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Handlers for 'better columns' subset (the handler class performs grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on LogisticRegression\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1870s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1865s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 118 out of 120 | elapsed:    7.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    7.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1396s.) Setting batch_size=2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on KNeighborsClassifier\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  35 | elapsed:    0.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  35 | elapsed:    0.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  35 | elapsed:    0.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  35 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0249s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0459s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on GaussianNB\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Performing Grid Search on SVC\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0539s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on DecisionTreeClassifier\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on RandomForestClassifier\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 118 out of 120 | elapsed:   18.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on GradientBoostingClassifier\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  80 | elapsed:   27.7s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   31.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Grid Search on MLPClassifier\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  80 | elapsed:  2.5min remaining:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Voting Classifier using best models...\n",
      "\n",
      "Performing Grid Search on VotingClassifier\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:   10.2s remaining:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   10.9s remaining:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   11.6s remaining:    4.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': LogisticRegression(C=100, max_iter=1000, multi_class='multinomial'), 'knn': KNeighborsClassifier(n_neighbors=15), 'gauss': GaussianNB(), 'svc': SVC(C=100, gamma=1, kernel='linear'), 'd_tree': DecisionTreeClassifier(criterion='entropy', max_depth=4), 'r_forest': RandomForestClassifier(max_features=0.25, min_samples_split=6, n_estimators=50), 'g_boost': GradientBoostingClassifier(learning_rate=0.05), 'nn': MLPClassifier(activation='tanh', hidden_layer_sizes=(50, 25, 5),\n",
      "              learning_rate='adaptive', max_iter=10000, solver='sgd'), 'voting': VotingClassifier(estimators=[('lr',\n",
      "                              LogisticRegression(C=100, max_iter=1000,\n",
      "                                                 multi_class='multinomial')),\n",
      "                             ('knn', KNeighborsClassifier(n_neighbors=15)),\n",
      "                             ('gauss', GaussianNB()),\n",
      "                             ('svc', SVC(C=100, gamma=1, kernel='linear')),\n",
      "                             ('d_tree',\n",
      "                              DecisionTreeClassifier(criterion='entropy',\n",
      "                                                     max_depth=4)),\n",
      "                             ('r_forest',\n",
      "                              RandomForestClassifier(max_features=0.25,\n",
      "                                                     min_samples_split=6,\n",
      "                                                     n_estimators=50)),\n",
      "                             ('g_boost',\n",
      "                              GradientBoostingClassifier(learning_rate=0.05)),\n",
      "                             ('nn',\n",
      "                              MLPClassifier(activation='tanh',\n",
      "                                            hidden_layer_sizes=(50, 25, 5),\n",
      "                                            learning_rate='adaptive',\n",
      "                                            max_iter=10000, solver='sgd'))])} {'lr': <__main__.ModelHandler object at 0x000002DBDAB71070>, 'knn': <__main__.ModelHandler object at 0x000002DBDE32DEB0>, 'gauss': <__main__.ModelHandler object at 0x000002DBD1868760>, 'svc': <__main__.ModelHandler object at 0x000002DBD18681C0>, 'd_tree': <__main__.ModelHandler object at 0x000002DBD17C9F10>, 'r_forest': <__main__.ModelHandler object at 0x000002DBD1868130>, 'g_boost': <__main__.ModelHandler object at 0x000002DBD1805F40>, 'nn': <__main__.ModelHandler object at 0x000002DBD99E1BE0>, 'voting': <__main__.ModelHandler object at 0x000002DBD186B7F0>}\n"
     ]
    }
   ],
   "source": [
    "models = [log_tuple, knn_tuple, gauss_tuple, svc_tuple, d_tree_tuple, r_forest_tuple, g_boost_tuple, nn_tuple]\n",
    "handlers_better_cols = return_handlers(data_better_cols, *models)\n",
    "\n",
    "print(handlers_better_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics and Confusion Matrix for model \"nn\"\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.49      0.54        68\n",
      "           1       0.59      0.71      0.65        72\n",
      "\n",
      "    accuracy                           0.60       140\n",
      "   macro avg       0.60      0.60      0.59       140\n",
      "weighted avg       0.60      0.60      0.59       140\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stats for 'bad columns' data (\"voting\" model)\n",
    "analyze_visualize('nn', handlers_bad_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics and Confusion Matrix for model \"nn\"\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       121\n",
      "           1       0.82      0.81      0.81       149\n",
      "\n",
      "    accuracy                           0.80       270\n",
      "   macro avg       0.79      0.80      0.79       270\n",
      "weighted avg       0.80      0.80      0.80       270\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stats for 'better columns' data (\"voting\" model)\n",
    "analyze_visualize('nn', handlers_better_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.ModelHandler'>: it's not the same object as __main__.ModelHandler",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-200-4049579effed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandlers_bad_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"models\\\\bad_col_models\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msave_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandlers_better_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"models\\\\better_col_models\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-199-276125612092>\u001b[0m in \u001b[0;36msave_models\u001b[1;34m(handlers, folder_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mnow_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y_%m_%d__%H_%M'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{folder_path}\\\\{model_name}__{now_str}.sav\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\dskul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[0mNumpyPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[0mNumpyPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dskul\\appdata\\local\\programs\\python\\python39\\lib\\pickle.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dskul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dskul\\appdata\\local\\programs\\python\\python39\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[1;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dskul\\appdata\\local\\programs\\python\\python39\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    683\u001b[0m                     \"args[0] from __newobj__ args has the wrong class\")\n\u001b[0;32m    684\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m             \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m             \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNEWOBJ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dskul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dskul\\appdata\\local\\programs\\python\\python39\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dskul\\appdata\\local\\programs\\python\\python39\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_type\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m   1124\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1126\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_global\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mFunctionType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_global\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dskul\\appdata\\local\\programs\\python\\python39\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_global\u001b[1;34m(self, obj, name)\u001b[0m\n\u001b[0;32m   1071\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mobj2\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m                 raise PicklingError(\n\u001b[0m\u001b[0;32m   1074\u001b[0m                     \u001b[1;34m\"Can't pickle %r: it's not the same object as %s.%s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m                     (obj, module_name, name))\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <class '__main__.ModelHandler'>: it's not the same object as __main__.ModelHandler"
     ]
    }
   ],
   "source": [
    "save_models(handlers_bad_cols, \"models\\\\bad_col_models\")\n",
    "save_models(handlers_better_cols, \"models\\\\better_col_models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
